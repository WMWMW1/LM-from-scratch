# 从零开始的语言模型 - 开源学习仓库

## 简介

欢迎来到从零开始的语言模型开源学习仓库！本仓库旨在复现一些基于transformer架构的语言模型，我们的最终目标是构建一个类似于[transformers](https://github.com/huggingface/transformers)的库，使得研究人员和爱好者能够更容易地使用和扩展这些强大的模型。

## Motivation

- **复现经典**: 我们专注于复现transformer架构的经典语言模。
- **易于扩展**: 通过提供清晰的代码结构和文档，我们鼓励社区贡献，使得库不断增长和改进。
- **教育目的**: 除了作为一个研究工具，本仓库也旨在教育那些对深度学习和自然语言处理感兴趣的人，了解模型的内部工作原理。

## 开始使用

1. 克隆仓库到本地
2. 安装依赖项
3. 运行示例脚本

详细的安装和使用指南请参见我们的[安装指南](./INSTALL.md)和[使用手册](./USAGE.md)。

## 如何贡献

我们欢迎所有形式的贡献，包括但不限于新模型的复现、代码改进、文档补充等。请参见我们的[贡献指南](./CONTRIBUTING.md)了解更多信息。

## Todo 表格

| 任务             | 状态    | 预计完成时间 |
|----------------|------|----------|
| 简易tokenizer   | 进行中 |           |
| 模块化tokenizer   | 待开始 |           |
| 模块化agent   | 待开始 |           |
| RLHF Trainer   | 待开始 |           |
| SFT Trainer    | 待开始 |                |
| Trainer 基础架构 | 待开始 |               |

## 许可证

本项目采用 [MIT 许可证](./LICENSE)。我们鼓励广泛的使用和分发。

## 联系我们

如果你有任何问题或者建议，请通过Issue或者Pull Request与我们联系。
